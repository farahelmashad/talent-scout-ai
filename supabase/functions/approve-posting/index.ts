import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from "https://esm.sh/@supabase/supabase-js@2";
import { pipeline } from "https://cdn.jsdelivr.net/npm/@xenova/transformers@2.5.0"; 

const corsHeaders = {
Â  'Access-Control-Allow-Origin': '*',
Â  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

// Qdrant configuration
const QDRANT_URL = Deno.env.get('QDRANT_URL')!;
const QDRANT_API_KEY = Deno.env.get('QDRANT_API_KEY')!;
const JOB_POSTINGS_COLLECTION = 'job_postings_cluster';
const EMPLOYEES_COLLECTION = 'employees';

// ðŸš¨ FIX 2: Switched to a 384-dimension model supported on the Supabase Edge Runtime
const EMBEDDING_MODEL = 'Supabase/gte-small'; 

// ðŸš¨ FIX 3: Initialize the local inference pipeline globally for efficiency
const embeddingPipe = await pipeline(
Â  'feature-extraction',
Â  EMBEDDING_MODEL,
);

// Promotion model API endpoint
const PROMOTION_MODEL_URL = Deno.env.get('PROMOTION_MODEL_URL') || '';

serve(async (req) => {
Â  if (req.method === 'OPTIONS') {
Â  Â  return new Response(null, { headers: corsHeaders });
Â  }

Â  try {
Â  Â  const { naturalPosting, structuredData, originalInput } = await req.json();
Â  Â  
Â  Â  const supabaseClient = createClient(
Â  Â  Â  Deno.env.get('SUPABASE_URL') ?? '',
Â  Â  Â  Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') ?? ''
Â  Â  );

Â  Â  const parsedData = JSON.parse(structuredData);
Â  Â  
Â  Â  // Process skills into array
Â  Â  const skills = typeof parsedData.skills === 'string' 
Â  Â  Â  ? parsedData.skills.split(',').map((s: string) => s.trim())
Â  Â  Â  : parsedData.skills || [];
Â  Â  
Â  Â  // Save to Supabase
Â  Â  const { data: posting, error } = await supabaseClient
Â  Â  Â  .from('job_postings')
Â  Â  Â  .insert({
Â  Â  Â  Â  job_title: originalInput.jobTitle,
Â  Â  Â  Â  career_level: originalInput.careerLevel,
Â  Â  Â  Â  location: originalInput.location,
Â  Â  Â  Â  department: originalInput.department,
Â  Â  Â  Â  key_skills: originalInput.keySkills ? originalInput.keySkills.split(',').map((s: string) => s.trim()) : [],
Â  Â  Â  Â  natural_posting: naturalPosting,
Â  Â  Â  Â  structured_data: parsedData,
Â  Â  Â  })
Â  Â  Â  .select()
Â  Â  Â  .single();

Â  Â  if (error) throw error;

Â  Â  console.log('âœ… Saved to Supabase:', posting.id);

Â  Â  // Create embedding text for job posting
Â  Â  const embeddingText = createEmbeddingText(parsedData, naturalPosting);
Â  Â  console.log('ðŸ“ Created embedding text, length:', embeddingText.length);
Â  Â  
Â  Â  // Get embedding from local pipeline
Â  Â  console.log('ðŸ”„ Getting 384D embedding from Edge Runtime...');
Â  Â  const embedding = await getEmbedding(embeddingText);
Â  Â  console.log('âœ… Got embedding, dimensions:', embedding.length);
Â  Â  
Â  Â  // Process departments
Â  Â  const departmentKeywords = processDepartments(parsedData.job_categories || '');
Â  Â  const primaryDepartment = departmentKeywords[0] || 'General';

Â  Â  // Upload job posting to Qdrant
Â  Â  const qdrantPayload = {
Â  Â  Â  points: [{
Â  Â  Â  Â  id: posting.id,
Â  Â  Â  Â  vector: embedding,
Â  Â  Â  Â  payload: {
Â  Â  Â  Â  Â  job_id: posting.id,
Â  Â  Â  Â  Â  status: 'active',
Â  Â  Â  Â  Â  date_created: new Date().toISOString().split('T')[0],
Â  Â  Â  Â  Â  title: parsedData.title,
Â  Â  Â  Â  Â  company: parsedData.company,
Â  Â  Â  Â  Â  job_type: parsedData.job_type,
Â  Â  Â  Â  Â  work_setting: parsedData.work_setting,
Â  Â  Â  Â  Â  location: parsedData.location,
Â  Â  Â  Â  Â  experience_needed: parsedData.experience_needed,
Â  Â  Â  Â  Â  career_level: parsedData.career_level,
Â  Â  Â  Â  Â  education_level: parsedData.education_level,
Â  Â  Â  Â  Â  job_categories: departmentKeywords,
Â  Â  Â  Â  Â  department: primaryDepartment,
Â  Â  Â  Â  Â  skills: skills,
Â  Â  Â  Â  Â  job_description: naturalPosting,
Â  Â  Â  Â  Â  job_requirements: naturalPosting,
Â  Â  Â  Â  Â  embedding_text: embeddingText
Â  Â  Â  Â  }
Â  Â  Â  }]
Â  Â  };

Â  Â  const qdrantResponse = await fetch(
Â  Â  Â  `${QDRANT_URL}/collections/${JOB_POSTINGS_COLLECTION}/points?wait=true`,
Â  Â  Â  {
Â  Â  Â  Â  method: 'PUT',
Â  Â  Â  Â  headers: {
Â  Â  Â  Â  Â  'Content-Type': 'application/json',
Â  Â  Â  Â  Â  'api-key': QDRANT_API_KEY,
Â  Â  Â  Â  },
Â  Â  Â  Â  body: JSON.stringify(qdrantPayload),
Â  Â  Â  }
Â  Â  );

Â  Â  if (!qdrantResponse.ok) {
Â  Â  Â  const errorText = await qdrantResponse.text();
Â  Â  Â  console.error('Qdrant job posting upload failed:', errorText);
Â  Â  Â  throw new Error(`Qdrant job posting upload failed: ${errorText}`);
Â  Â  }

Â  Â  console.log('âœ… Job posting uploaded to Qdrant');

Â  Â  // Query Qdrant for similar employees
Â  Â  console.log('ðŸ” Querying Qdrant for similar employees...');
Â  Â  const similarEmployeesData = await querySimilarEmployees(embedding);

Â  Â  console.log(`âœ… Found ${similarEmployeesData.length} similar employees`);
Â  Â  if (similarEmployeesData.length > 0) {
Â  Â  Â  console.log('First match:', JSON.stringify(similarEmployeesData[0]));
Â  Â  }

Â  Â  // Get promotion predictions for matched employees
Â  Â  let similarEmployees = similarEmployeesData;
Â  Â  
Â  Â  if (PROMOTION_MODEL_URL && similarEmployeesData.length > 0) {
Â  Â  Â  try {
Â  Â  Â  Â  similarEmployees = await addPromotionPredictions(similarEmployeesData);
Â  Â  Â  Â  console.log('âœ… Added promotion predictions');
Â  Â  Â  } catch (error) {
Â  Â  Â  Â  console.error('âš ï¸ Promotion prediction failed, using similarity only:', error);
Â  Â  Â  }
Â  Â  } else {
Â  Â  Â  console.log('âš ï¸ No promotion model URL configured, using mock predictions');
Â  Â  Â  similarEmployees = similarEmployeesData.map(emp => ({
Â  Â  Â  Â  ...emp,
Â  Â  Â  Â  promotion_probability: Math.random() * 0.4 + 0.6
Â  Â  Â  }));
Â  Â  }

Â  Â  return new Response(JSON.stringify({ 
Â  Â  Â  posting, 
Â  Â  Â  similarEmployees,
Â  Â  Â  qdrant_upload_success: true 
Â  Â  }), {
Â  Â  Â  headers: { ...corsHeaders, 'Content-Type': 'application/json' },
Â  Â  });
Â  } catch (error) {
Â  Â  const errorMessage = error instanceof Error ? error.message : 'Unknown error occurred';
Â  Â  console.error('Error in approve-posting:', errorMessage);
Â  Â  return new Response(JSON.stringify({ error: errorMessage }), {
Â  Â  Â  status: 500,
Â  Â  Â  headers: { ...corsHeaders, 'Content-Type': 'application/json' },
Â  Â  });
Â  }
});

// Helper functions (createEmbeddingText and processDepartments remain the same)
function createEmbeddingText(structuredData: any, naturalPosting: string): string {
Â  const skills = typeof structuredData.skills === 'string'
Â  Â  ? structuredData.skills
Â  Â  : Array.isArray(structuredData.skills)
Â  Â  ? structuredData.skills.join(', ')
Â  Â  : '';

Â  return `
Job Title: ${structuredData.title}
Job Type: ${structuredData.job_type}
Work Setting: ${structuredData.work_setting}
Location: ${structuredData.location}
Experience Level: ${structuredData.experience_needed}
Career Level: ${structuredData.career_level}
Education Required: ${structuredData.education_level}
Department/Categories: ${structuredData.job_categories}
Required Skills: ${skills}

Job Description:
${naturalPosting}

Job Requirements:
${naturalPosting}
Â  `.trim();
}

function processDepartments(rawCategories: string): string[] {
Â  const processedString = rawCategories
Â  Â  .replace(/ - /g, ',')
Â  Â  .replace(/ \/ /g, ',')
Â  Â  .replace(/\//g, ',')
Â  Â  .replace(/-/g, ',');
Â  
Â  const keywords = processedString
Â  Â  .split(',')
Â  Â  .map(k => k.trim())
Â  Â  .filter(k => k.length > 0);
Â  
Â  return keywords.length > 0 ? keywords : ['General'];
}

// ðŸš¨ FIX 4: The fully rewritten getEmbedding function using local Deno inference
async function getEmbedding(text: string): Promise<number[]> {
Â  console.log(`ðŸ”„ Generating 384D embedding with local model: ${EMBEDDING_MODEL}...`);

Â  try {
Â  Â  // Generate the embedding using the local pipeline
Â  Â  const output = await embeddingPipe(text, {
Â  Â  Â  pooling: 'mean', // Mean pooling for sentence embeddings
Â  Â  Â  normalize: true, // Normalize the vector for cosine similarity
Â  Â  });
Â  Â  
Â  Â  // Convert the TypedArray output to a standard number array for Qdrant payload
Â  Â  const embedding = Array.from(output.data) as number[];
Â  Â  
Â  Â  // Final check for 384 dimensions
Â  Â  if (embedding.length !== 384) {
Â  Â  Â  throw new Error(`Model error: Expected 384 dimensions, got ${embedding.length}`);
Â  Â  }

Â  Â  console.log('âœ… Local Edge Embedding successful! Dimensions: 384');
Â  Â  return embedding;

Â  } catch (error) {
Â  Â  const errorMessage = error instanceof Error ? error.message : 'Unknown local inference error';
Â  Â  console.error('Local Embedding failed:', errorMessage);
Â  Â  // Re-throw a clear error for the main handler to catch
Â  Â  throw new Error(`Embedding generation failed: ${errorMessage}`);
Â  }
}


// ðŸš¨ FIX 5: Removed the now-unused meanPoolTokens function.


async function querySimilarEmployees(jobEmbedding: number[]): Promise<any[]> {
Â  const searchPayload = {
Â  Â  vector: jobEmbedding,
Â  Â  limit: 5,
Â  Â  with_payload: true,
Â  Â  score_threshold: 0.5
Â  };

Â  const response = await fetch(
Â  Â  `${QDRANT_URL}/collections/${EMPLOYEES_COLLECTION}/points/search`,
Â  Â  {
Â  Â  Â  method: 'POST',
Â  Â  Â  headers: {
Â  Â  Â  Â  'Content-Type': 'application/json',
Â  Â  Â  Â  'api-key': QDRANT_API_KEY,
Â  Â  Â  },
Â  Â  Â  body: JSON.stringify(searchPayload),
Â  Â  }
Â  );

Â  if (!response.ok) {
Â  Â  const errorText = await response.text();
Â  Â  throw new Error(`Qdrant employee search failed: ${errorText}`);
Â  }

Â  const result = await response.json();
Â  
Â  const employees = result.result.map((item: any) => ({
Â  Â  id: item.id,
Â  Â  name: item.payload.name || 'Unknown',
Â  Â  department: item.payload.department || 'Unknown',
Â  Â  current_role: item.payload.current_role || item.payload.designation || 'Unknown',
Â  Â  email: item.payload.email || `employee${item.id}@company.com`,
Â  Â  similarity_score: item.score,
Â  Â  previous_year_rating: item.payload.previous_year_rating || 0,
Â  Â  length_of_service: item.payload.length_of_service || 0,
Â  Â  awards_won: item.payload.awards_won || 0,
Â  Â  no_of_trainings: item.payload.no_of_trainings || 0,
Â  Â  avg_training_score: item.payload.avg_training_score || 0,
Â  Â  KPIs_met_more_than_80: item.payload.KPIs_met_more_than_80 || 0,
Â  }));

Â  return employees;
}

async function addPromotionPredictions(employees: any[]): Promise<any[]> {
Â  const employeeFeatures = employees.map(emp => ({
Â  Â  previous_year_rating: emp.previous_year_rating,
Â  Â  length_of_service: emp.length_of_service,
Â  Â  awards_won: emp.awards_won,
Â  Â  no_of_trainings: emp.no_of_trainings,
Â  Â  avg_training_score: emp.avg_training_score,
Â  Â  KPIs_met_more_than_80: emp.KPIs_met_more_than_80,
Â  Â  department: emp.department
Â  }));

Â  const response = await fetch(PROMOTION_MODEL_URL, {
Â  Â  method: 'POST',
Â  Â  headers: {
Â  Â  Â  'Content-Type': 'application/json',
Â  Â  },
Â  Â  body: JSON.stringify({ employees: employeeFeatures }),
Â  });

Â  if (!response.ok) {
Â  Â  throw new Error('Promotion prediction API failed');
Â  }

Â  const predictions = await response.json();

Â  return employees.map((emp, index) => ({
Â   ...emp,
Â  Â  promotion_probability: predictions[index]?.probability || 0.5,
Â  }));
}